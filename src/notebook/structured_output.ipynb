{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "question = 'Hello'\n",
    "content = f''' \n",
    "    Based on the query from user:\n",
    "    \n",
    "    {question}\n",
    "    \n",
    "    Which one is the best agent for procesing ? :\n",
    "    \n",
    "    Agents:\n",
    "    - `HandbookAgent`: This agent serves for the informations related to career, employee, working time, promotion in IT, etc... in the internal handbook of Nexcel Solutions\n",
    "    - `OriginalAgent`: This agent supports for casual conservation in other areas like greeting cooking, police, education, etc... \n",
    "    - `BettingKnowledgeAgent`: This agent executes the tasks according to betting knowledge questions in Nexcel Solutions\n",
    "    \n",
    "'''\n",
    "message = [{\"role\": \"user\", \"content\": content}]\n",
    "format = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"agent\": {\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"agent\"\n",
    "    ]\n",
    "  }\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.2:latest',\n",
    "    messages=message,\n",
    "    stream=False,\n",
    "    format=format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context = \"The total hours of ‘Late in – Early out’ will be counted in system and affect employee’s Annual Leave balance.In a month, if the employee is late for work and/or leaves work early 4 times, which will be counted as a violation, an email reminder from HR will be issued. The third violation within 12 months will incur a warning letter from the Management. For example:  First violation: August 2018Second violation: December 2018Third violation: July 2019  First violation: August 2018Second violation: December 2018Third violation: July 2019→ Warning letter will be issued from the Management.  When the total ‘Late-in’ and ‘Early-out’ (will be accumulated over months and across the years) is up to 4 hours, a half-day Annual Leave of employee will be deducted, for example:  December 2018: total ‘Late-in’ and ‘Early-out’ is 3 hours.January 2019: total ‘Late-in’ and ‘Early-out’ is 1 hour.  December 2018: total ‘Late-in’ and ‘Early-out’ is 3 hours.January 2019: total ‘Late-in’ and ‘Early-out’ is 1 hour.→ HR will issue a confirmation paper to inform that half-day Annual Leave of the employee is going to be deducted.  This limitation is not applied to manager level.\"\n",
    "\n",
    "content = f''' \n",
    "    Please summary the context to the short: \n",
    "    \n",
    "    {context}\n",
    "'''\n",
    "message = [{\"role\": \"user\", \"content\": content}]\n",
    "format = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"summary\": {\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"summary\"\n",
    "    ]\n",
    "  }\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.2:latest',\n",
    "    messages=message,\n",
    "    stream=False,\n",
    "    format=format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f''' \n",
    "    \n",
    "    This answer is correct or not:\n",
    "    \n",
    "    1 + 69 = 70\n",
    "    \n",
    "    Please answer Yes or No\n",
    "'''\n",
    "message = [{\"role\": \"user\", \"content\": content}]\n",
    "format = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"decision\": {\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"decision\"\n",
    "    ]\n",
    "  }\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.2:latest',\n",
    "    messages=message,\n",
    "    stream=False,\n",
    "    format=format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"decision\": \"Yes\" }\\n  '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    {\n",
    "        \"url\": \"https://nexcel.info/employee-handbook-2/\",\n",
    "        \"headers\": [\n",
    "            \"2. TERMS AND CONDITIONS\",\n",
    "            \"2.6. Limitation of late-in and early-out request.\"\n",
    "        ],\n",
    "        \"content\": \"\\nThe total hours of \\u2018Late in \\u2013 Early out\\u2019 will be counted in system and affect employee\\u2019s Annual Leave balance.\\nIn a month, if the employee is late for work and/or leaves work early 4 times, which will be counted as a violation, an email reminder from HR will be issued. The third violation within 12 months will incur a warning letter from the Management. For example:  \\nFirst violation: August 2018\\nSecond violation: December 2018\\nThird violation: July 2019  \\nFirst violation: August 2018\\nSecond violation: December 2018\\nThird violation: July 2019\\n\\u2192 Warning letter will be issued from the Management.  \\nWhen the total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 (will be accumulated over months and across the years) is up to 4 hours, a half-day Annual Leave of employee will be deducted, for example:  \\nDecember 2018: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 3 hours.\\nJanuary 2019: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 1 hour.  \\nDecember 2018: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 3 hours.\\nJanuary 2019: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 1 hour.\\n\\u2192 HR will issue a confirmation paper to inform that half-day Annual Leave of the employee is going to be deducted.  \\nThis limitation is not applied to manager level.\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://nexcel.info/employee-handbook-2/\",\n",
    "        \"headers\": [\n",
    "            \"2. TERMS AND CONDITIONS\",\n",
    "            \"2.7. Abuse of working time\"\n",
    "        ],\n",
    "        \"content\": \"\\nEmployees are not allowed to abuse working hours. Scenarios that would be considered abusing working hours may include but are not limited to:\\n* Alter the work schedule (e.g. extending the 1-hour lunch break, going out or going to pantry to have breakfast after Check in, or staying longer in pantry/smoking area for chatting, etc.). Please be reminded that drinks and fast food are offered to help you get more energy for working, not for exploiting duty time.\\n* Check out after playing sport. You must check out first and then enjoy sports, clubs, etc.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Handbook(BaseModel):\n",
    "    url: str\n",
    "    title: str\n",
    "    headers: str\n",
    "    content: str\n",
    "\n",
    "class HandbookList(BaseModel):\n",
    "    countries: List[Handbook]\n",
    "\n",
    "with open(r\"D:\\Desktop\\chatbot4group\\src\\notebook\\employee.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "context = f''' \n",
    "    Please provide url, title, headers, content for each sessions in this html file:\n",
    "    {html_content}\n",
    "'''\n",
    "\n",
    "response = chat(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': context,\n",
    "        }\n",
    "    ],\n",
    "    model='llama3.2:latest',\n",
    "    format=HandbookList.model_json_schema(),\n",
    ")\n",
    "\n",
    "country_list = HandbookList.model_validate_json(response.message.content)\n",
    "print(country_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Handbook(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    keywords: List[str]\n",
    "\n",
    "class HandbookList(BaseModel):\n",
    "    label: List[Handbook] = []\n",
    "\n",
    "info = text[1]['content']\n",
    "context = f''' \n",
    "    Generate at least 100 questions and answers based on the following information:\n",
    "    {info}\n",
    "'''\n",
    "country_list = HandbookList()\n",
    "\n",
    "while len(country_list.label) == 0:\n",
    "    \n",
    "    print('Empty: ', len(country_list.label))\n",
    "    \n",
    "    response = chat(\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': context,\n",
    "            }\n",
    "        ],\n",
    "        model='llama3.2:latest',\n",
    "        format=HandbookList.model_json_schema(),\n",
    "    )\n",
    "\n",
    "    country_list = HandbookList.model_validate_json(response.message.content)\n",
    "    \n",
    "print(country_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def write_json(documents: List[Dict[str, str]], path: str):\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(documents, json_file)\n",
    "        \n",
    "def load_json(path_save_documents) -> Dict[str, Any]:\n",
    "    with open(path_save_documents, 'r') as json_file:\n",
    "        documents = json.load(json_file)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_json('./generated_example.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_documents = [*documents, *country_list.dict()['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(concat_documents, path='./generated_example.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords=['senior software engineer', 'how to', 'become']\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Handbook(BaseModel):\n",
    "    keywords: List[str]\n",
    "\n",
    "# with open(r\"D:\\Desktop\\chatbot4group\\src\\notebook\\employee.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     html_content = file.read()\n",
    "\n",
    "query = \"How to become a senior software engineer ?\"\n",
    "context = f''' \n",
    "    Please extract the keywords from this sentences: {query} \n",
    "'''\n",
    "\n",
    "response = chat(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': context,\n",
    "        }\n",
    "    ],\n",
    "    model='llama3.2:latest',\n",
    "    format=Handbook.model_json_schema(),\n",
    ")\n",
    "\n",
    "country_list = Handbook.model_validate_json(response.message.content)\n",
    "print(country_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_json('./generated_example.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert2df(documents):\n",
    "    \n",
    "    questions = [question['question'] for question in documents]\n",
    "    answers = [answer['answer'] for answer in documents]\n",
    "    keywords = [keyword['keywords'] for keyword in documents]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'questions': questions,\n",
    "        'answers': answers,\n",
    "        'keywords': keywords\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents = convert2df(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "data = Dataset.from_pandas(df_documents)\n",
    "data.push_to_hub(\"leonpham1208/nexcel-solutions-handbook\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"leonpham1208/nexcel-solutions-handbook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
