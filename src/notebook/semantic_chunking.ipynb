{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [{\n",
    "        \"url\": \"https://nexcel.info/employee-handbook-2/\",\n",
    "        \"headers\": [\n",
    "            \"2. TERMS AND CONDITIONS\",\n",
    "            \"2.6. Limitation of late-in and early-out request.\"\n",
    "        ],\n",
    "        \"content\": \"\\nThe total hours of \\u2018Late in \\u2013 Early out\\u2019 will be counted in system and affect employee\\u2019s Annual Leave balance.\\nIn a month, if the employee is late for work and/or leaves work early 4 times, which will be counted as a violation, an email reminder from HR will be issued. The third violation within 12 months will incur a warning letter from the Management. For example:  \\nFirst violation: August 2018\\nSecond violation: December 2018\\nThird violation: July 2019  \\nFirst violation: August 2018\\nSecond violation: December 2018\\nThird violation: July 2019\\n\\u2192 Warning letter will be issued from the Management.  \\nWhen the total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 (will be accumulated over months and across the years) is up to 4 hours, a half-day Annual Leave of employee will be deducted, for example:  \\nDecember 2018: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 3 hours.\\nJanuary 2019: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 1 hour.  \\nDecember 2018: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 3 hours.\\nJanuary 2019: total \\u2018Late-in\\u2019 and \\u2018Early-out\\u2019 is 1 hour.\\n\\u2192 HR will issue a confirmation paper to inform that half-day Annual Leave of the employee is going to be deducted.  \\nThis limitation is not applied to manager level.\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://nexcel.info/employee-handbook-2/\",\n",
    "        \"headers\": [\n",
    "            \"2. TERMS AND CONDITIONS\",\n",
    "            \"2.7. Abuse of working time\"\n",
    "        ],\n",
    "        \"content\": \"\\nEmployees are not allowed to abuse working hours. Scenarios that would be considered abusing working hours may include but are not limited to:\\n* Alter the work schedule (e.g. extending the 1-hour lunch break, going out or going to pantry to have breakfast after Check in, or staying longer in pantry/smoking area for chatting, etc.). Please be reminded that drinks and fast food are offered to help you get more energy for working, not for exploiting duty time.\\n* Check out after playing sport. You must check out first and then enjoy sports, clubs, etc.\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Data model\n",
    "class GeneratePropositions(BaseModel):\n",
    "    \"\"\"List of all the propositions in a given document\"\"\"\n",
    "\n",
    "    propositions: List[str] = Field(\n",
    "        description=\"List of propositions (factual, self-contained, and concise information)\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOllama(model=\"llama3.2:latest\", temperature=0)\n",
    "structured_llm= llm.with_structured_output(GeneratePropositions)\n",
    "\n",
    "# Few shot prompting --- We can add more examples to make it good\n",
    "proposition_examples = [\n",
    "    {\"document\": \n",
    "        \"In 1969, Neil Armstrong became the first person to walk on the Moon during the Apollo 11 mission.\", \n",
    "     \"propositions\": \n",
    "        ['Neil Armstrong was an astronaut.', 'Neil Armstrong walked on the Moon in 1969.', 'Neil Armstrong was the first person to walk on the Moon.', 'Neil Armstrong walked on the Moon during the Apollo 11 mission.', 'The Apollo 11 mission occurred in 1969.']\n",
    "    },\n",
    "]\n",
    "\n",
    "example_proposition_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{document}\"),\n",
    "        (\"ai\", \"{propositions}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_proposition_prompt,\n",
    "    examples = proposition_examples,\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"Please break down the following text into simple, self-contained propositions. Ensure that each proposition meets the following criteria:\n",
    "\n",
    "    1. Express a Single Fact: Each proposition should state one specific fact or claim.\n",
    "    2. Be Understandable Without Context: The proposition should be self-contained, meaning it can be understood without needing additional context.\n",
    "    3. Use Full Names, Not Pronouns: Avoid pronouns or ambiguous references; use full entity names.\n",
    "    4. Include Relevant Dates/Qualifiers: If applicable, include necessary dates, times, and qualifiers to make the fact precise.\n",
    "    5. Contain One Subject-Predicate Relationship: Focus on a single subject and its corresponding action or attribute, without conjunctions or multiple clauses.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{document}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "proposition_generator = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Please break down the following text into simple, self-contained propositions. Ensure that each proposition meets the following criteria:\\n\\n    1. Express a Single Fact: Each proposition should state one specific fact or claim.\\n    2. Be Understandable Without Context: The proposition should be self-contained, meaning it can be understood without needing additional context.\\n    3. Use Full Names, Not Pronouns: Avoid pronouns or ambiguous references; use full entity names.\\n    4. Include Relevant Dates/Qualifiers: If applicable, include necessary dates, times, and qualifiers to make the fact precise.\\n    5. Contain One Subject-Predicate Relationship: Focus on a single subject and its corresponding action or attribute, without conjunctions or multiple clauses.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'document': 'In 1969, Neil Armstrong became the first person to walk on the Moon during the Apollo 11 mission.', 'propositions': ['Neil Armstrong was an astronaut.', 'Neil Armstrong walked on the Moon in 1969.', 'Neil Armstrong was the first person to walk on the Moon.', 'Neil Armstrong walked on the Moon during the Apollo 11 mission.', 'The Apollo 11 mission occurred in 1969.']}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['document', 'propositions'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template='{document}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['propositions'], input_types={}, partial_variables={}, template='{propositions}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template='{document}'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatOllama(model='llama3.2:latest', temperature=0.0), kwargs={'tools': [{'type': 'function', 'function': {'name': 'GeneratePropositions', 'description': 'List of all the propositions in a given document', 'parameters': {'type': 'object', 'properties': {'propositions': {'description': 'List of propositions (factual, self-contained, and concise information)', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['propositions']}}}], 'structured_output_format': {'kwargs': {'method': 'function_calling'}, 'schema': {'type': 'function', 'function': {'name': 'GeneratePropositions', 'description': 'List of all the propositions in a given document', 'parameters': {'type': 'object', 'properties': {'propositions': {'description': 'List of propositions (factual, self-contained, and concise information)', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['propositions']}}}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.GeneratePropositions'>])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposition_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "test = \"Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal).\"\n",
    "# proposition_generator.invoke({\"document\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total hours of ‘Late in – Early out’ will be counted in system and affect employee’s Annual Leave balance.In a month, if the employee is late for work and/or leaves work early 4 times, which will be counted as a violation, an email reminder from HR will be issued. The third violation within 12 months will incur a warning letter from the Management. For example:  First violation: August 2018Second violation: December 2018Third violation: July 2019  First violation: August 2018Second violation: December 2018Third violation: July 2019→ Warning letter will be issued from the Management.  When the total ‘Late-in’ and ‘Early-out’ (will be accumulated over months and across the years) is up to 4 hours, a half-day Annual Leave of employee will be deducted, for example:  December 2018: total ‘Late-in’ and ‘Early-out’ is 3 hours.January 2019: total ‘Late-in’ and ‘Early-out’ is 1 hour.  December 2018: total ‘Late-in’ and ‘Early-out’ is 3 hours.January 2019: total ‘Late-in’ and ‘Early-out’ is 1 hour.→ HR will issue a confirmation paper to inform that half-day Annual Leave of the employee is going to be deducted.  This limitation is not applied to manager level.\n"
     ]
    }
   ],
   "source": [
    "print(text[0]['content'].replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The total hours of 'Late in \\u2013 Early out' will be counted in the system.\",\n",
      "  \"The total hours affect employee's Annual Leave balance.\",\n",
      "  \"In a month, if the employee is late for work and/or leaves work early 4 times, an email reminder from HR will be issued.\",\n",
      "  \"The third violation within 12 months will incur a warning letter from the Management.\",\n",
      "  \"The first violation occurred in August 2018.\",\n",
      "  \"The second violation occurred in December 2018.\",\n",
      "  \"The third violation occurred in July 2019.\",\n",
      "  \"Warning letter will be issued from the Management.\",\n",
      "  \"When the total 'Late-in' and 'Early-out' is up to 4 hours, a half-day Annual Leave of employee will be deducted.\",\n",
      "  \"The total 'Late-in' and 'Early-out' will be accumulated over months and across the years.\",\n",
      "  \"An example of a total 'Late-in' and 'Early-out' is 3 hours in December 2018.\",\n",
      "  \"In January 2019, the total 'Late-in' and 'Early-out' is 1 hour.\",\n",
      "  \"HR will issue a confirmation paper to inform that half-day Annual Leave of the employee is going to be deducted.\",\n",
      "  \"This limitation is not applied to manager level.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_name = \"chentong00/propositionizer-wiki-flan-t5-large\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "title = \"Supervised learning\"\n",
    "section = \"\"\n",
    "content = text[0]['content'].replace('\\n', '')\n",
    "\n",
    "input_text = f\"Title: {title}. Section: {section}. Content: {content}\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids.to(device), max_new_tokens=512).cpu()\n",
    "\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "try:\n",
    "    prop_list = json.loads(output_text)\n",
    "except:\n",
    "    prop_list = []\n",
    "    print(\"[ERROR] Failed to parse output text as JSON.\")\n",
    "print(json.dumps(prop_list, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "propositions = [] # Store all the propositions from the document\n",
    "doc_splits = [t['content'] for t in text]\n",
    "source = [t['url'] for t in text]\n",
    "\n",
    "for i in range(len(doc_splits)):\n",
    "    print(doc_splits[i])\n",
    "    response = proposition_generator.invoke({\"document\": doc_splits[i]}) # Creating proposition\n",
    "    for proposition in response.propositions:\n",
    "        propositions.append(Document(page_content=proposition, metadata={\"Title\": \"Employee Handbook\", \"Source\": source[i], \"chunk_id\": i+1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
